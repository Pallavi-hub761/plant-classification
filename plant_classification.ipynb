{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from torch.optim import Adam\n",
        "from glob import glob\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "5CR70rHkZjfp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Unzip the data files\n",
        "train_zip_path = '/content/Train-20241109T060353Z-002.zip'\n",
        "test_zip_path = '/content/Test-20241109T060349Z-002.zip'\n",
        "data_dir = '/content/unzipped_data'\n",
        "\n",
        "train_dir = os.path.join(data_dir, 'Train')\n",
        "test_dir = os.path.join(data_dir, 'Test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(train_dir)\n",
        "\n",
        "with zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(test_dir)"
      ],
      "metadata": {
        "id": "1Y9W9bI2e10s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load CSV files\n",
        "train_labels = pd.read_csv('/content/train (2).csv')\n",
        "test_labels = pd.read_csv('/content/test (1).csv')"
      ],
      "metadata": {
        "id": "97C2-TyTe3t5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Map paths to image files\n",
        "train_paths = glob(os.path.join(train_dir, '**', '*.jpg'), recursive=True)\n",
        "test_paths = glob(os.path.join(test_dir, '**', '*.jpg'), recursive=True)\n",
        "\n",
        "train_path_dict = {os.path.basename(path): path for path in train_paths}\n",
        "test_path_dict = {os.path.basename(path): path for path in test_paths}\n",
        "\n",
        "train_labels['path'] = train_labels['path'].map(train_path_dict)\n",
        "test_labels['path'] = test_labels['path'].map(test_path_dict)\n",
        "\n",
        "# Drop any rows where the path could not be found\n",
        "train_labels.dropna(subset=['path'], inplace=True)\n",
        "test_labels.dropna(subset=['path'], inplace=True)\n",
        "\n",
        "# Print unique labels in the training set for verification\n",
        "print(\"Unique labels in training set:\", train_labels['label'].unique())\n",
        "\n",
        "# Map labels to a continuous range if needed\n",
        "label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(train_labels['label'].unique()))}\n",
        "train_labels['label'] = train_labels['label'].map(label_mapping)\n",
        "\n",
        "# Update num_classes to reflect the remapped labels\n",
        "num_classes = train_labels['label'].nunique()\n",
        "print(\"Updated number of classes:\", num_classes)\n",
        "\n",
        "# Verify that labels are within the correct range\n",
        "assert train_labels['label'].max() == num_classes - 1, \"Labels are out of range for the number of classes.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0FE7foSe9Sx",
        "outputId": "25280282-9ba1-4e8e-d000-2534747b8854"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in training set: [22 18 40 25  5 14  1 16 30  9  7 12 19 24 33 26 15  0 38 34  4 29 13 43\n",
            " 28 36 27 37  3 41  8 17  2 21 10 20 23 31 32  6 42 35 39]\n",
            "Updated number of classes: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Dataset class\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None, is_test=False):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx]['path']\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if not self.is_test:\n",
        "            label = self.dataframe.iloc[idx]['label']\n",
        "            return image, label\n",
        "        else:\n",
        "            return image, img_path\n"
      ],
      "metadata": {
        "id": "6iOTncmufKiv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "PSOnRaRUfMob"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Datasets and DataLoaders\n",
        "train_dataset = ImageDataset(train_labels, transform=transform)\n",
        "test_dataset = ImageDataset(test_labels, transform=transform, is_test=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "EyllsmzVfNFa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Model definition\n",
        "class EfficientNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(EfficientNetClassifier, self).__init__()\n",
        "        self.base_model = models.efficientnet_b0(pretrained=True)\n",
        "        self.base_model.classifier = nn.Sequential(\n",
        "            nn.Linear(self.base_model.classifier[1].in_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n"
      ],
      "metadata": {
        "id": "ulNygaHSfNTZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Model initialization\n",
        "num_classes = train_labels['label'].nunique()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = EfficientNetClassifier(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-Mc7_0NfNf5",
        "outputId": "3e3c0aab-d395-46da-ddc9-7162471cb432"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Training function\n",
        "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in tqdm(dataloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device).long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(dataloader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "D28B81refNqJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Train the model\n",
        "train_model(model, train_loader, criterion, optimizer, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asZNxQAFfNso",
        "outputId": "e2822b39-8a52-41b8-904a-369d4a49c8e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:41<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.6055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:40<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5], Loss: 0.7379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:40<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5], Loss: 0.4308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:40<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5], Loss: 0.2776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:40<00:00,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Loss: 0.1852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Save the original model to Google Drive\n",
        "drive_model_path = '/content/drive/MyDrive/saved_models/efficientnet_model.pth'\n",
        "os.makedirs(os.path.dirname(drive_model_path), exist_ok=True)\n",
        "torch.save(model.state_dict(), drive_model_path)\n",
        "print(f\"Original model saved to {drive_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCpq0crOfNvK",
        "outputId": "e46b49ce-09a0-4960-cc1a-33c0d22a925e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model saved to /content/drive/MyDrive/saved_models/efficientnet_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Convert to TorchScript and save\n",
        "model_scripted = torch.jit.script(model)\n",
        "model_scripted = model_scripted.to(device)\n",
        "drive_scripted_path = '/content/drive/MyDrive/saved_models/efficientnet_model_scripted.pth'\n",
        "torch.jit.save(model_scripted, drive_scripted_path)\n",
        "print(f\"Scripted model saved to {drive_scripted_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCqJ2m6DfNy7",
        "outputId": "31ad178e-dc3d-45a8-d5ec-f49201b5f82a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scripted model saved to /content/drive/MyDrive/saved_models/efficientnet_model_scripted.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 13: Model evaluation for training (optional step)\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device).long()\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "5fjqnkFaf7KP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 14: Calculate F1 score and accuracy\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Training Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Training F1 Score (weighted): {f1:.4f}\")\n",
        "\n",
        "model_scripted = torch.jit.script(model)\n",
        "model_scripted = model_scripted.to(device)\n",
        "print(\"Model converted to TorchScript for optimized inference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vTDLyfaf7UX",
        "outputId": "18a302af-d8f7-4fe4-f058-8f456c6eb022"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9822\n",
            "Training F1 Score (weighted): 0.9817\n",
            "Model converted to TorchScript for optimized inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 15: Make predictions on the test set using the optimized model\n",
        "test_preds = []\n",
        "test_paths = []\n",
        "\n",
        "model_scripted.eval()\n",
        "with torch.no_grad():\n",
        "    for images, paths in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model_scripted(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        test_preds.extend(preds.cpu().numpy())\n",
        "        test_paths.extend(paths)\n",
        "\n",
        "# Create DataFrame for submission\n",
        "test_results = pd.DataFrame({'path': test_paths, 'label': test_preds})\n",
        "test_results['path'] = test_results['path'].apply(os.path.basename)\n",
        "\n",
        "# Save to CSV\n",
        "test_results.to_csv('/content/test_predictions.csv', index=False)\n",
        "print(\"Test predictions saved to test_predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9B64YEXfN2Q",
        "outputId": "1486aa3d-6648-449a-a100-bada4fea1446"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions saved to test_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}